# ANP Ports Vessel Scraper ğŸ‡²ğŸ‡¦

A comprehensive web scraper for monitoring Moroccan port activities from the Agence Nationale des Ports (ANP), specifically targeting vessel movements, port operations, and maritime traffic data.

## ğŸ¯ Features

### Core Functionality
- **ğŸ” Smart API Scraping**: Scrapes ANP vessel movement data via REST API
- **ğŸ¯ Intelligent Data Filtering**: Advanced filtering logic for vessel types and operators
- **ğŸ§¹ Duplicate Prevention**: Robust deduplication using vessel IDs and timestamps
- **ğŸ“Š Beautiful Dashboard**: Modern web interface with real-time data visualization
- **ğŸ”„ API Integration**: RESTful API for programmatic access

### Data Filtering Logic
- **Group A (Vessel Types)**: **OPTIONAL** - VRAQUIER, CHIMIQUIER, TANKER, etc.
- **Group B (Operators)**: **OPTIONAL** - OCP, MARSA MAROC, SOMAPORT, etc.
- **Group C (Ports/Locations)**: **MANDATORY** - At least one required
  - **Group C**: Ports (CASABLANCA, SAFI, TANGER MED, etc.)

### Advanced Features
- **ğŸ¨ Color-coded Categories**: Visual display of vessel types and operators in dashboard
- **ğŸ“… Real-time Updates**: Live data from ANP API
- **ğŸ”§ CLI Tools**: Command-line interface for automation
- **ğŸ“ˆ Export Capabilities**: CSV export with filtering options
- **ğŸŒ Vercel Deployment**: Ready for cloud deployment

## ğŸš€ **Deployment & Usage**

### **Local Development (Recommended for Full Functionality)**

For complete functionality with persistent data storage:

```bash
# Clone the repository
git clone <repository-url>
cd anp-ports-scraper

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp env.example .env
# Edit .env with your ANP API credentials if needed

# Run the scraper
python3 run_scraper.py --force-update

# Start the web dashboard
python3 src/main.py
# Open http://localhost:8000
```

**âœ… Local Benefits:**
- Persistent data storage in `data/` folder
- Full scraping history maintained
- No data loss between runs
- Complete functionality

### **Vercel Deployment (Limited Functionality)**

The project can be deployed to Vercel, but with **significant limitations**:

**âš ï¸ Vercel Limitations:**
- Data is stored in `/tmp` directory (temporary)
- Data gets cleared between function invocations
- No persistent storage between requests
- Dashboard shows 0 results after page refresh

**ğŸ”§ Vercel Setup:**
```bash
# Deploy to Vercel
vercel --prod

# Environment variables in Vercel dashboard:
ANP_API_URL=https://www.anp.org.ma//_vti_bin/WS/Service.svc/mvmnv/all
```

**ğŸ“Š Vercel Use Case:**
- Testing the scraper functionality
- Demonstrating the filtering logic
- Temporary data viewing
- **NOT suitable for production data collection**

## ğŸ“Š Dashboard Features

### Main Interface
- **ğŸ“ˆ KPI Cards**: Total vessels, active vessels, last update time, status
- **ğŸ” Advanced Filters**: Date range, vessel type, operator, port, search
- **ğŸ“‹ Interactive Table**: Sortable results with color-coded categories
- **ğŸ“Š Charts**: Timeline and vessel type visualizations

### Category Display
- **ğŸ›¡ï¸ Blue badges**: Vessel types (VRAQUIER, CHIMIQUIER, TANKER, etc.)
- **ğŸ§ª Orange badges**: Operators (OCP, MARSA MAROC, etc.)
- **ğŸŒ Green badges**: Ports/Locations (CASABLANCA, SAFI, etc.)

### Actions
- **ğŸ”„ Update Now**: Trigger immediate data update from ANP API
- **ğŸ“¥ Export CSV**: Download filtered results
- **ğŸ‘ï¸ View Details**: Inspect raw vessel data
- **ğŸ”— External Links**: Direct links to vessel tracking

## ğŸ”§ API Endpoints

### Core Endpoints
```bash
# Trigger data update
POST /api/update?force_update=true

# Get dashboard data
GET /api/dashboard-data

# Get specific vessel
GET /api/vessels/{vessel_id}

# Export CSV
GET /api/export/csv?start_date=2025-01-01&end_date=2025-12-31

# Get filter options
GET /api/operators
GET /api/ports  
GET /api/vessel-types
```

### Response Format
```json
{
  "status": "success",
  "message": "Successfully updated vessel data",
  "new_vessels": 15,
  "total_vessels": 45,
  "duration_seconds": 2.5,
  "last_update": "2025-01-20T10:30:00Z"
}
```

## ğŸ“ Project Structure

```
anp-ports-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ scraper.py             # Core scraping logic
â”‚   â”œâ”€â”€ matcher.py             # Data filtering engine
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ anp_api.py         # ANP API client
â”‚   â”‚   â””â”€â”€ __init__.py        # Package initialization
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ index.html         # Dashboard UI
â”‚       â””â”€â”€ app.js             # Frontend JavaScript
â”œâ”€â”€ data/                      # Data storage
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ env.example               # Environment configuration
â”œâ”€â”€ run_scraper.py            # CLI interface
â”œâ”€â”€ test_scraper.py           # Test suite
â”œâ”€â”€ vercel.json               # Vercel configuration
â””â”€â”€ README.md                 # This file
```

## ğŸ¯ Data Categories

### Group A: Vessel Types (Optional)
- VRAQUIER, CHIMIQUIER, TANKER, PORTE CONTENEUR
- PASSAGERS, GAZIER, PETROLIER, CONVENTIONEL
- Specialized vessel categories

### Group B: Operators (Optional)  
- OCP, MARSA MAROC, SOMAPORT, SOSIPO
- MASS CEREALES, COMATAM, AGEMAFRIC
- Shipping companies and agencies

### Group C: Ports/Locations (Mandatory)
- **Major Ports**: CASABLANCA, SAFI, TANGER MED, AGADIR
- **International Ports**: VANCOUVER, BEAUMONT, NECOCHEA, MALTA
- **European Ports**: DUNKERQUE, ALMERIA, MARSEILLE, VALENCIA

## ğŸ” Filtering Logic

The scraper uses advanced filtering with:

### Data Validation
- âœ… Valid vessel names and IMO numbers
- âœ… Proper timestamp formatting
- âœ… Geographic coordinate validation
- âŒ Invalid or corrupted data filtered out

### Filtering Requirements
- **Group C (Ports/Locations)** must have at least 1 match
- **Groups A or B** must have at least 1 match combined
- Vessels matching these criteria are saved and displayed

## ğŸ“Š Data Storage

### JSON Format
```json
{
  "nOM_NAVIREField": "EPIPHANIA",
  "nUMERO_ESCALEField": 201463131,
  "nUMERO_LLOYDField": "9104469",
  "oPERATEURField": "MASS CEREALES",
  "pROVField": "VANCOUVER",
  "sITUATIONField": "EN RADE",
  "tYP_NAVIREField": "VRAQUIER",
  "cONSIGNATAIREField": "TRADE NAV",
  "dATE_SITUATIONField": "/Date(1755817200000+0100)/",
  "scraped_at": "2025-01-20T10:30:00.123456",
  "filter_details": {
    "groups_matched": 2,
    "match_score": 3,
    "vessel_type_keywords": ["VRAQUIER"],
    "operator_keywords": [],
    "port_location_keywords": ["VANCOUVER"],
    "matched_snippets": ["VRAQUIER vessel EPIPHANIA from VANCOUVER"]
  }
}
```

### Deduplication
- **Primary**: Vessel Name + Escale Number
- **Secondary**: Lloyd Number + Timestamp
- **Automatic**: Built into scraping process
- **Manual**: `--clean-duplicates` CLI command

## ğŸŒ Deployment

### Local Development
```bash
# Start development server
cd src && python3 main.py

# Access at http://localhost:8000
```

### Vercel Deployment
```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
vercel --prod

# Configure environment variables in Vercel dashboard
```

### Environment Variables
```bash
# Required: ANP API endpoint
ANP_API_URL=https://www.anp.org.ma//_vti_bin/WS/Service.svc/mvmnv/all

# Optional: Application settings
LOG_LEVEL=INFO
DATA_DIR=./data
UPDATE_INTERVAL=300  # 5 minutes
```

## ğŸ”§ Configuration

### Update Parameters
- **Update Interval**: 5 minutes by default (configurable)
- **Data Retention**: 30 days by default (configurable)
- **API Rate Limiting**: Respectful requests with delays

### Category Customization
Edit `src/matcher.py` to modify category groups:
```python
# Add new vessel types
self.vessel_type_keywords.append("NewVesselType")

# Add new operators  
self.operator_keywords.append("NewOperator")

# Add new ports
self.port_location_keywords.append("NewPort")
```

## ğŸ› Troubleshooting

### Common Issues

#### No Vessels Found
- Check API endpoint availability
- Verify filtering logic
- Use `--stats` to see what's in the database

#### Duplicates
- Run `python3 run_scraper.py --clean-duplicates`
- Deduplication is automatic in new updates

#### Server Not Starting
- Check if port 8000 is available
- Ensure all dependencies are installed
- Check Python version (3.8+ required)

#### ANP API Connection Issues
- ANP may have rate limiting
- Check API endpoint availability
- Verify network connectivity

### Debug Mode
```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
python3 run_scraper.py --force-update
```

## ğŸ“ˆ Performance

### Metrics
- **Update Speed**: ~2-3 seconds for full API response
- **Match Rate**: 100% with current filtering logic
- **Deduplication**: Automatic and efficient
- **Memory Usage**: Low (streaming JSON processing)

### Optimization
- Efficient API calls with proper caching
- Smart deduplication prevents data bloat
- Efficient filtering with compiled regex
- Respectful API usage with delays

## ğŸ¤ Contributing

### Development Setup
```bash
# Fork the repository
git clone <your-fork>
cd anp-ports-scraper

# Create feature branch
git checkout -b feature/new-feature

# Make changes and test
python3 run_scraper.py --force-update

# Commit and push
git commit -m "Add new feature"
git push origin feature/new-feature
```

### Code Style
- Follow PEP 8 for Python code
- Use meaningful variable names
- Add docstrings to functions
- Include type hints where appropriate

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- ANP (Agence Nationale des Ports) for providing public maritime data
- FastAPI for the excellent web framework
- Tabler for the beautiful UI components
- The open-source community for inspiration and tools

## ğŸ“ Support

For questions, issues, or contributions:
- Open an issue on GitHub
- Check the troubleshooting section
- Review the API documentation at `/docs`

---

**Built with â¤ï¸ for Moroccan port monitoring**
